import pandas as pd
import zipfile

dfs = {}  # íŒŒì¼ ì´ë¦„ â†’ DataFrame ì €ì¥ ë”•ì…”ë„ˆë¦¬

with zipfile.ZipFile("result.zip") as z:
    for filename in z.namelist():  # ZIP ì•ˆ ëª¨ë“  íŒŒì¼ ì´ë¦„
        if filename.endswith(".csv"):  # CSVë§Œ ì„ íƒ
            with z.open(filename) as f:
                dfs[filename] = pd.read_csv(f)

# ê²°ê³¼
for name, df in dfs.items():
    print(name, df.shape)


# pd.set_option('display.max_colwidth', None)  ----------------------------ë°ì´í„° í”„ë ˆì„ì—ì„œ íŒë¡€ë¬¸ ëª¨ë“  ê¸€ì ë³´ì—¬ì£¼ëŠ” ì„¤ì •

df = dfs["result_1.csv"]  # ------------------------ê°ì ë§¡ìœ¼ì‹ ê±¸ë¡œ ë³€ê²½í•´ì£¼ì‹œë©´ë©ë‹ˆë‹¤.

import re
import pandas as pd
import asyncio
from concurrent.futures import ThreadPoolExecutor
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from tqdm import tqdm


from langsmith import traceable
from dotenv import load_dotenv
import os

# ---------- LANGSMITH_API_KEY í™•ì¸ ----------

load_dotenv()
print(os.environ.get("LANGSMITH_API_KEY"))

# ---------- 1ï¸âƒ£ ëª¨ë¸ ì„¤ì • ----------
llm = ChatOpenAI(model="gpt-4o-mini-2024-07-18", temperature=0)


# ---------- 2ï¸âƒ£ ê²°ê³¼ ìŠ¤í‚¤ë§ˆ ----------
class LegalRoleSummary(BaseModel):
    ë°°ìƒì±…ì„: str = Field(description="ë°°ìƒ ì±…ì„ì´ ëˆ„êµ¬ì—ê²Œ ìˆëŠ”ì§€: ì›ê³  / í”¼ê³  / ì—†ìŒ")
    ì£¼ì œ: str = Field(description="ì£¼ì œ í‚¤ì›Œë“œ ì˜ˆ: ë¶€ë™ì‚°, ì´ˆìƒê¶Œ ë“±")
    ìŸì : str = Field(description="ìŸì  í‚¤ì›Œë“œ ì˜ˆ: ì„ëŒ€ì°¨ ê³„ì•½ í•´ì§€, ëª…ì˜ˆí›¼ì† ë“±")
    ë‹¹ì‚¬ì1_ì—­í• : str = Field(
        description="ì²« ë²ˆì§¸ ë‹¹ì‚¬ìì˜ ì—­í• ëª…: ì›ê³  / ê²€ì‚¬ / ì‹ ì²­ì¸ ë“±"
    )
    ë‹¹ì‚¬ì1_ì£¼ì¥: str = Field(description="ì²« ë²ˆì§¸ ë‹¹ì‚¬ìì˜ ì£¼ì¥ ìš”ì•½")
    ë‹¹ì‚¬ì2_ì—­í• : str = Field(
        description="ë‘ ë²ˆì§¸ ë‹¹ì‚¬ìì˜ ì—­í• ëª…: í”¼ê³  / í”¼ê³ ì¸ / ìƒëŒ€ë°© ë“±"
    )
    ë‹¹ì‚¬ì2_ì£¼ì¥: str = Field(description="ë‘ ë²ˆì§¸ ë‹¹ì‚¬ìì˜ ì£¼ì¥ ìš”ì•½")
    ì¬íŒë¶€_íŒë‹¨: str = Field(description="ë²•ì›ì˜ íŒë‹¨ ìš”ì•½")
    ê²°ê³¼: str = Field(description="ê²°ê³¼ í‚¤ì›Œë“œ ì˜ˆ: ì›ê³  ìŠ¹ì†Œ, í”¼ê³  ì¼ë¶€ íŒ¨ì†Œ ë“±")
    ìš”ì•½: str = Field(description="ì‚¬ê±´ ì „ì²´ ìš”ì•½ í•œ ë¬¸ì¥")


parser = PydanticOutputParser(pydantic_object=LegalRoleSummary)


# ---------- 3ï¸âƒ£ ì „ì²˜ë¦¬ í•¨ìˆ˜ ----------
def preprocess_text(text):
    text = re.sub(r"ã€ì›ê³ [^ã€‘]*ã€‘", "", text)
    text = re.sub(r"ã€í”¼ê³ [^ã€‘]*ã€‘", "", text)
    text = re.sub(r"ã€ì›ì‹¬íŒê²°[^ã€‘]*ã€‘", "", text)
    reason_match = re.search(r"ã€ì´\s*ìœ ã€‘(.+?)(íŒê²°í•œë‹¤|íŒê²°í•¨|ëŒ€ë²•ê´€)", text, re.S)
    if reason_match:
        text = reason_match.group(1).strip()
    return text


# ---------- 4ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ----------
system_prompt = """
ë‹¹ì‹ ì€ íŒë¡€ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì‚¬ê±´ íŒë¡€ë‚´ìš©ì„ ì½ê³  JSONìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.

{row_info}

- ë°°ìƒ ì±…ì„: ì›ê³  / í”¼ê³  / ì—†ìŒ
- ì£¼ì œ í‚¤ì›Œë“œ: í•œ ë‹¨ì–´ (ì˜ˆ: ì´ˆìƒê¶Œ, ì†í•´ë°°ìƒ)
- ìŸì  í‚¤ì›Œë“œ: í•œ ë‹¨ì–´ ë˜ëŠ” ì§§ì€ êµ¬ (ì˜ˆ: ì„ëŒ€ì°¨ í•´ì§€)
- ë‹¹ì‚¬ì1 ì—­í• : (ì˜ˆ: ì›ê³ , ê²€ì‚¬)
- ë‹¹ì‚¬ì1 ì£¼ì¥: ì§§ê²Œ ìš”ì•½
- ë‹¹ì‚¬ì2 ì—­í• : (ì˜ˆ: í”¼ê³ , í”¼ê³ ì¸)
- ë‹¹ì‚¬ì2 ì£¼ì¥: ì§§ê²Œ ìš”ì•½
- ì¬íŒë¶€ íŒë‹¨: ê°„ê²°í•˜ê²Œ ìš”ì•½
- ê²°ê³¼: ê°„ë‹¨íˆ (ì˜ˆ: ì›ê³  ìŠ¹ì†Œ)
- ìš”ì•½: í•œ ë¬¸ì¥
"""

prompt = PromptTemplate(
    input_variables=["row_info", "format_instructions"],
    template=system_prompt + "\n{format_instructions}",
)

chain = LLMChain(llm=llm, prompt=prompt, output_parser=parser)
partial_vars = {"format_instructions": parser.get_format_instructions()}

# ---------- 5ï¸âƒ£ ë¹„ë™ê¸° ì²˜ë¦¬ í•¨ìˆ˜ ----------

# ì—ëŸ¬ë‚¬ì„ ê²½ìš° ì‚¬ê±´ë²ˆí˜¸ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
error_list = []


def process_row(idx, case_num, case_text):
    clean_text = preprocess_text(case_text)
    try:
        result = chain.invoke({"row_info": clean_text, **partial_vars})
        summary = result["text"].model_dump()
        summary["case_num"] = case_num
        # return result['text'].model_dump() # Pydantic ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        return summary
    except Exception as e:
        error_list.append(case_num)
        return {"case_num": case_num, "error": str(e)}


async def process_batch(df, start_index=0, batch_size=1000, max_workers=5):
    end_index = min(start_index + batch_size, len(df))
    results = []

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        loop = asyncio.get_event_loop()
        tasks = [
            loop.run_in_executor(
                executor,
                process_row,
                idx,
                df.loc[idx, "ì‚¬ê±´ë²ˆí˜¸"],
                df.loc[idx, "íŒë¡€ë‚´ìš©"],
            )
            for idx in range(start_index, end_index)
        ]
        for f in tqdm(
            asyncio.as_completed(tasks),
            total=len(tasks),
            desc="ğŸ”„ ë³‘ë ¬ ìš”ì•½ ì§„í–‰ì¤‘",
            unit="ê±´",
        ):
            result = await f
            results.append(result)

    output_file = f"legal_summary_{start_index}_{end_index - 1}.csv"
    pd.DataFrame(results).to_csv(output_file, index=False)
    print(f"âœ… {output_file} ì €ì¥ ì™„ë£Œ ({start_index} ~ {end_index - 1}ê±´)")
    print("-------------------------")
    print(f"âŒ ì—ëŸ¬ ì‚¬ê±´ë²ˆí˜¸ ëª©ë¡ : {error_list}")


# asyncio.run(process_batch(df, start_index=0, batch_size=5, max_workers=5)) #---------ì‹¤í–‰ ì½”ë“œ
# start_indexê°’ì´ë‘ batch_sizeë§Œ ë³€ê²½í•´ì„œ ì›í•˜ëŠ” ê±´ìˆ˜ë§Œí¼ ëŒë ¤ì£¼ì‹œë©´ë©ë‹ˆë‹¤.
# ì—ëŸ¬ë‚˜ë©´ ë°‘ì— ì½”ë“œ ì‚¬ìš©í•˜ì„¸ìš”.


import nest_asyncio  # --------------- ì£¼í”¼í„° ì‹¤í–‰ì½”ë“œì…ë‹ˆë‹¤.

nest_asyncio.apply()
await process_batch(df, start_index=600, batch_size=400, max_workers=5)

# í™•ì¸ìš©
split_df = pd.read_csv("./legal_summary_600_.csv")
split_df.shape
split_df.head()
