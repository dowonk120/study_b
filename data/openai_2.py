import re
import pandas as pd
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
import time
from tqdm import tqdm  # âœ… ì§„í–‰ë¥  í‘œì‹œ

# ---------- 1ï¸âƒ£ ëª¨ë¸ ì„¤ì • ----------
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# ---------- 2ï¸âƒ£ ê²°ê³¼ ìŠ¤í‚¤ë§ˆ ----------
class LegalRoleSummary(BaseModel):
    ë°°ìƒì±…ì„: str = Field(description="ë°°ìƒ ì±…ì„ì´ ëˆ„êµ¬ì—ê²Œ ìˆëŠ”ì§€: ì›ê³  / í”¼ê³  / ì—†ìŒ")
    ì£¼ì œ: str = Field(description="ì£¼ì œ í‚¤ì›Œë“œ ì˜ˆ: ë¶€ë™ì‚°, ì´ˆìƒê¶Œ ë“±")
    ìŸì : str = Field(description="ìŸì  í‚¤ì›Œë“œ ì˜ˆ: ì„ëŒ€ì°¨ ê³„ì•½ í•´ì§€, ëª…ì˜ˆí›¼ì† ë“±")
    ë‹¹ì‚¬ì1_ì—­í• : str = Field(description="ì²« ë²ˆì§¸ ë‹¹ì‚¬ìì˜ ì—­í• ëª…: ì›ê³  / ê²€ì‚¬ / ì‹ ì²­ì¸ ë“±")
    ë‹¹ì‚¬ì1_ì£¼ì¥: str = Field(description="ì²« ë²ˆì§¸ ë‹¹ì‚¬ìì˜ ì£¼ì¥ ìš”ì•½")
    ë‹¹ì‚¬ì2_ì—­í• : str = Field(description="ë‘ ë²ˆì§¸ ë‹¹ì‚¬ìì˜ ì—­í• ëª…: í”¼ê³  / í”¼ê³ ì¸ / ìƒëŒ€ë°© ë“±")
    ë‹¹ì‚¬ì2_ì£¼ì¥: str = Field(description="ë‘ ë²ˆì§¸ ë‹¹ì‚¬ìì˜ ì£¼ì¥ ìš”ì•½")
    ì¬íŒë¶€_íŒë‹¨: str = Field(description="ë²•ì›ì˜ íŒë‹¨ ìš”ì•½")
    ê²°ê³¼: str = Field(description="ê²°ê³¼ í‚¤ì›Œë“œ ì˜ˆ: ì›ê³  ìŠ¹ì†Œ, í”¼ê³  ì¼ë¶€ íŒ¨ì†Œ ë“±")
    ìš”ì•½: str = Field(description="ì‚¬ê±´ ì „ì²´ ìš”ì•½ í•œ ë¬¸ì¥")

parser = PydanticOutputParser(pydantic_object=LegalRoleSummary)

# ---------- 3ï¸âƒ£ ì „ì²˜ë¦¬ í•¨ìˆ˜ ----------
def preprocess_text(text):
    text = re.sub(r'ã€ì›ê³ [^ã€‘]*ã€‘', '', text)
    text = re.sub(r'ã€í”¼ê³ [^ã€‘]*ã€‘', '', text)
    text = re.sub(r'ã€ì›ì‹¬íŒê²°[^ã€‘]*ã€‘', '', text)
    reason_match = re.search(r'ã€ì´\s*ìœ ã€‘(.+?)(íŒê²°í•œë‹¤|íŒê²°í•¨|ëŒ€ë²•ê´€)', text, re.S)
    if reason_match:
        text = reason_match.group(1).strip()
    return text

# ---------- 4ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ----------
system_prompt = """
ë‹¹ì‹ ì€ íŒë¡€ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì‚¬ê±´ íŒë¡€ë‚´ìš©ì„ ì½ê³  JSONìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.

{row_info}

- ë°°ìƒ ì±…ì„: ì›ê³  / í”¼ê³  / ì—†ìŒ
- ì£¼ì œ í‚¤ì›Œë“œ: í•œ ë‹¨ì–´ (ì˜ˆ: ì´ˆìƒê¶Œ, ì†í•´ë°°ìƒ)
- ìŸì  í‚¤ì›Œë“œ: í•œ ë‹¨ì–´ ë˜ëŠ” ì§§ì€ êµ¬ (ì˜ˆ: ì„ëŒ€ì°¨ í•´ì§€)
- ë‹¹ì‚¬ì1 ì—­í• : (ì˜ˆ: ì›ê³ , ê²€ì‚¬)
- ë‹¹ì‚¬ì1 ì£¼ì¥: ì§§ê²Œ ìš”ì•½
- ë‹¹ì‚¬ì2 ì—­í• : (ì˜ˆ: í”¼ê³ , í”¼ê³ ì¸)
- ë‹¹ì‚¬ì2 ì£¼ì¥: ì§§ê²Œ ìš”ì•½
- ì¬íŒë¶€ íŒë‹¨: ê°„ê²°í•˜ê²Œ ìš”ì•½
- ê²°ê³¼: ê°„ë‹¨íˆ (ì˜ˆ: ì›ê³  ìŠ¹ì†Œ)
- ìš”ì•½: í•œ ë¬¸ì¥
"""

prompt = PromptTemplate(
    input_variables=["row_info", "format_instructions"],
    template=system_prompt + "\n{format_instructions}",
)

chain = LLMChain(llm=llm, prompt=prompt, output_parser=parser)
partial_vars = {"format_instructions": parser.get_format_instructions()}

# ---------- 5ï¸âƒ£ ì‚¬ìš©ì ì„¤ì • ----------
start_index = 0      # âœ… ì‹œì‘ ìœ„ì¹˜ (ë‹¤ìŒ ì‹¤í–‰ ì‹œ 1000, 2000ìœ¼ë¡œ ë³€ê²½)
batch_size = 1000    # âœ… ì²˜ë¦¬í•  ê±´ìˆ˜
end_index = min(start_index + batch_size, len(df))

# ---------- 6ï¸âƒ£ ì‹¤í–‰ ----------
results = []
for idx in tqdm(range(start_index, end_index), desc="ğŸ”„ ìš”ì•½ ì§„í–‰ì¤‘", unit="ê±´"):
    case_text = df.loc[idx, "íŒë¡€ë‚´ìš©"]
    clean_text = preprocess_text(case_text)

    try:
        result = chain.invoke({"row_info": clean_text, **partial_vars})
        results.append(result['text'].model_dump())
    except Exception as e:
        results.append({"error": str(e)})
    
    time.sleep(0.3)

# ---------- 7ï¸âƒ£ CSV ì €ì¥ ----------
output_file = f"legal_summary_{start_index}_{end_index}.csv"
pd.DataFrame(results).to_csv(output_file, index=False)
print(f"âœ… {output_file} ì €ì¥ ì™„ë£Œ ({start_index} ~ {end_index-1}ê±´)")
